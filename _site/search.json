[
  {
    "objectID": "03_data_wrangling.html",
    "href": "03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Data Wrangling:\n\nCode:\n\nlibrary(vroom)\nlibrary(data.table)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::between()         masks data.table::between()\n✖ readr::col_character()   masks vroom::col_character()\n✖ readr::col_date()        masks vroom::col_date()\n✖ readr::col_datetime()    masks vroom::col_datetime()\n✖ readr::col_double()      masks vroom::col_double()\n✖ readr::col_factor()      masks vroom::col_factor()\n✖ readr::col_guess()       masks vroom::col_guess()\n✖ readr::col_integer()     masks vroom::col_integer()\n✖ readr::col_logical()     masks vroom::col_logical()\n✖ readr::col_number()      masks vroom::col_number()\n✖ readr::col_skip()        masks vroom::col_skip()\n✖ readr::col_time()        masks vroom::col_time()\n✖ readr::cols()            masks vroom::cols()\n✖ readr::date_names_lang() masks vroom::date_names_lang()\n✖ readr::default_locale()  masks vroom::default_locale()\n✖ dplyr::filter()          masks stats::filter()\n✖ dplyr::first()           masks data.table::first()\n✖ readr::fwf_cols()        masks vroom::fwf_cols()\n✖ readr::fwf_empty()       masks vroom::fwf_empty()\n✖ readr::fwf_positions()   masks vroom::fwf_positions()\n✖ readr::fwf_widths()      masks vroom::fwf_widths()\n✖ lubridate::hour()        masks data.table::hour()\n✖ lubridate::isoweek()     masks data.table::isoweek()\n✖ dplyr::lag()             masks stats::lag()\n✖ dplyr::last()            masks data.table::last()\n✖ readr::locale()          masks vroom::locale()\n✖ lubridate::mday()        masks data.table::mday()\n✖ lubridate::minute()      masks data.table::minute()\n✖ lubridate::month()       masks data.table::month()\n✖ readr::output_column()   masks vroom::output_column()\n✖ readr::problems()        masks vroom::problems()\n✖ lubridate::quarter()     masks data.table::quarter()\n✖ lubridate::second()      masks data.table::second()\n✖ purrr::transpose()       masks data.table::transpose()\n✖ lubridate::wday()        masks data.table::wday()\n✖ lubridate::week()        masks data.table::week()\n✖ lubridate::yday()        masks data.table::yday()\n✖ lubridate::year()        masks data.table::year()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\ncol_types <- list(\n  id = col_character(),\n  type = col_character(),\n  number = col_character(),\n  country = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  abstract = col_character(),\n  title = col_character(),\n  kind = col_character(),\n  num_claims = col_double(),\n  filename = col_character(),\n  withdrawn = col_double()\n)\n\npatent_tbl <- vroom(\n  file       = \"Patent_data_reduced/patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\nWarning: The following named parsers don't match the column names: type,\nnumber, country, abstract, title, kind, filename, withdrawn\n\npatent_assignee_tbl <- vroom(\n  file       = \"Patent_data_reduced/patent_assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\nWarning: The following named parsers don't match the column names: id, type,\nnumber, country, date, abstract, title, kind, num_claims, filename, withdrawn\n\nassignee_tbl <- vroom(\n  file       = \"Patent_data_reduced/assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\nWarning: The following named parsers don't match the column names: number,\ncountry, date, abstract, title, kind, num_claims, filename, withdrawn\n\nuspc_tbl <- vroom(\n  file       = \"Patent_data_reduced/uspc.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\nWarning: The following named parsers don't match the column names: id, type,\nnumber, country, date, abstract, title, kind, num_claims, filename, withdrawn\n\nsetDT(patent_tbl)\n\nsetDT(assignee_tbl)\n\nsetDT(patent_assignee_tbl)\n\nsetDT(uspc_tbl)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\nclass(assignee_tbl)\n\n[1] \"data.table\" \"data.frame\"\n\ncolnames(assignee_tbl)\n\n[1] \"id\"           \"type\"         \"organization\"\n\nsetnames(assignee_tbl, \"id\", \"assignee_id\")\n\ncombined_data_1 <- merge(x = assignee_tbl, y = patent_assignee_tbl,by    = \"assignee_id\")\n\n\n\n\n\ncolnames(patent_tbl)\n\n[1] \"id\"         \"date\"       \"num_claims\"\n\nsetnames(patent_tbl, \"id\", \"patent_id\")\n\ncombined_data_2 <- merge(x = combined_data_1, y = patent_tbl, by = \"patent_id\")\n\n\n\n\n\nuspc_tbl[, patent_id := as.character(patent_id)]\ncombined_data_3 <- merge(x = uspc_tbl, y = combined_data_1, by = \"patent_id\")\n\n\n\n\n\n# First challenge\n\nsetDT(combined_data_1)\n\npatent_counts <- combined_data_1[, .(n_patents = .N), by = .(assignee_id, organization)][order(-n_patents)]\n\ntop_10_patent_holders <- patent_counts[1:10]\n\nview(top_10_patent_holders)\n\n\n# Second challenge\n\naugust_data <- combined_data_2[month(date) == 8 & year(date) == 2014]\n\npatent_counts <- august_data[, .(num_patents = .N), by = organization]\n\ntop_10 <- patent_counts[order(-num_patents)][1:10]\n\nas.data.table(top_10)\n\n                                   organization num_patents\n 1: International Business Machines Corporation         718\n 2:               Samsung Electronics Co., Ltd.         524\n 3:                      Canon Kabushiki Kaisha         361\n 4:                       Microsoft Corporation         337\n 5:                            Sony Corporation         269\n 6:                                 Google Inc.         240\n 7:                       QUALCOMM Incorporated         223\n 8:                                  Apple Inc.         222\n 9:                    Kabushiki Kaisha Toshiba         213\n10:                         LG Electronics Inc.         211\n\nview(top_10)\n\n# Third challenge\n\n\npatent_counts <- combined_data_3[, .(num_patents = .N), by = organization]\n\ntop_10_companies <- patent_counts[order(-num_patents)][1:10]\n\ntop_10_patents <- combined_data_3[organization %in% top_10_companies$organization]\n\ntech_counts <- top_10_patents[, .(num_patents = .N), by = mainclass_id]\n\ntop_5_tech_classes <- tech_counts[order(-num_patents)][1:5]\n\nview(top_5_tech_classes)"
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Data Wrangling:\n\n1 Code:\n\nlibrary(vroom)\nlibrary(data.table)\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::between()         masks data.table::between()\n#> ✖ readr::col_character()   masks vroom::col_character()\n#> ✖ readr::col_date()        masks vroom::col_date()\n#> ✖ readr::col_datetime()    masks vroom::col_datetime()\n#> ✖ readr::col_double()      masks vroom::col_double()\n#> ✖ readr::col_factor()      masks vroom::col_factor()\n#> ✖ readr::col_guess()       masks vroom::col_guess()\n#> ✖ readr::col_integer()     masks vroom::col_integer()\n#> ✖ readr::col_logical()     masks vroom::col_logical()\n#> ✖ readr::col_number()      masks vroom::col_number()\n#> ✖ readr::col_skip()        masks vroom::col_skip()\n#> ✖ readr::col_time()        masks vroom::col_time()\n#> ✖ readr::cols()            masks vroom::cols()\n#> ✖ readr::date_names_lang() masks vroom::date_names_lang()\n#> ✖ readr::default_locale()  masks vroom::default_locale()\n#> ✖ dplyr::filter()          masks stats::filter()\n#> ✖ dplyr::first()           masks data.table::first()\n#> ✖ readr::fwf_cols()        masks vroom::fwf_cols()\n#> ✖ readr::fwf_empty()       masks vroom::fwf_empty()\n#> ✖ readr::fwf_positions()   masks vroom::fwf_positions()\n#> ✖ readr::fwf_widths()      masks vroom::fwf_widths()\n#> ✖ lubridate::hour()        masks data.table::hour()\n#> ✖ lubridate::isoweek()     masks data.table::isoweek()\n#> ✖ dplyr::lag()             masks stats::lag()\n#> ✖ dplyr::last()            masks data.table::last()\n#> ✖ readr::locale()          masks vroom::locale()\n#> ✖ lubridate::mday()        masks data.table::mday()\n#> ✖ lubridate::minute()      masks data.table::minute()\n#> ✖ lubridate::month()       masks data.table::month()\n#> ✖ readr::output_column()   masks vroom::output_column()\n#> ✖ readr::problems()        masks vroom::problems()\n#> ✖ lubridate::quarter()     masks data.table::quarter()\n#> ✖ lubridate::second()      masks data.table::second()\n#> ✖ purrr::transpose()       masks data.table::transpose()\n#> ✖ lubridate::wday()        masks data.table::wday()\n#> ✖ lubridate::week()        masks data.table::week()\n#> ✖ lubridate::yday()        masks data.table::yday()\n#> ✖ lubridate::year()        masks data.table::year()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\ncol_types <- list(\n  id = col_character(),\n  type = col_character(),\n  number = col_character(),\n  country = col_character(),\n  date = col_date(\"%Y-%m-%d\"),\n  abstract = col_character(),\n  title = col_character(),\n  kind = col_character(),\n  num_claims = col_double(),\n  filename = col_character(),\n  withdrawn = col_double()\n)\n\npatent_tbl <- vroom(\n  file       = \"Patent_data_reduced/patent.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: type,\n#> number, country, abstract, title, kind, filename, withdrawn\n\npatent_assignee_tbl <- vroom(\n  file       = \"Patent_data_reduced/patent_assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: id, type,\n#> number, country, date, abstract, title, kind, num_claims, filename, withdrawn\n\nassignee_tbl <- vroom(\n  file       = \"Patent_data_reduced/assignee.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: number,\n#> country, date, abstract, title, kind, num_claims, filename, withdrawn\n\nuspc_tbl <- vroom(\n  file       = \"Patent_data_reduced/uspc.tsv\", \n  delim      = \"\\t\", \n  col_types  = col_types,\n  na         = c(\"\", \"NA\", \"NULL\")\n)\n\n#> Warning: The following named parsers don't match the column names: id, type,\n#> number, country, date, abstract, title, kind, num_claims, filename, withdrawn\n\nsetDT(patent_tbl)\n\nsetDT(assignee_tbl)\n\nsetDT(patent_assignee_tbl)\n\nsetDT(uspc_tbl)\n\n#> Warning: One or more parsing issues, call `problems()` on your data frame for details,\n#> e.g.:\n#>   dat <- vroom(...)\n#>   problems(dat)\n\nclass(assignee_tbl)\n\n#> [1] \"data.table\" \"data.frame\"\n\ncolnames(assignee_tbl)\n\n#> [1] \"id\"           \"type\"         \"organization\"\n\nsetnames(assignee_tbl, \"id\", \"assignee_id\")\n\ncombined_data_1 <- merge(x = assignee_tbl, y = patent_assignee_tbl,by    = \"assignee_id\")\n\n\n\n\n\ncolnames(patent_tbl)\n\n#> [1] \"id\"         \"date\"       \"num_claims\"\n\nsetnames(patent_tbl, \"id\", \"patent_id\")\n\ncombined_data_2 <- merge(x = combined_data_1, y = patent_tbl, by = \"patent_id\")\n\n\n\n\n\nuspc_tbl[, patent_id := as.character(patent_id)]\ncombined_data_3 <- merge(x = uspc_tbl, y = combined_data_1, by = \"patent_id\")\n\n\n\n\n\n# First challenge\n\nsetDT(combined_data_1)\n\npatent_counts <- combined_data_1[, .(n_patents = .N), by = .(assignee_id, organization)][order(-n_patents)]\n\ntop_10_patent_holders <- patent_counts[1:10]\n\nview(top_10_patent_holders)\n\n\n# Second challenge\n\naugust_data <- combined_data_2[month(date) == 8 & year(date) == 2014]\n\npatent_counts <- august_data[, .(num_patents = .N), by = organization]\n\ntop_10 <- patent_counts[order(-num_patents)][1:10]\n\nas.data.table(top_10)\n\n\n\n  \n\n\nview(top_10)\n\n# Third challenge\n\n\npatent_counts <- combined_data_3[, .(num_patents = .N), by = organization]\n\ntop_10_companies <- patent_counts[order(-num_patents)][1:10]\n\ntop_10_patents <- combined_data_3[organization %in% top_10_companies$organization]\n\ntech_counts <- top_10_patents[, .(num_patents = .N), by = mainclass_id]\n\ntop_5_tech_classes <- tech_counts[order(-num_patents)][1:5]\n\nview(top_5_tech_classes)"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Data Visualization:"
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html#mapping-the-time-course-of-the-cumulative-covid-19-cases",
    "href": "content/01_journal/04_data_visualization.html#mapping-the-time-course-of-the-cumulative-covid-19-cases",
    "title": "Data Visualization",
    "section": "1.1 Mapping the time course of the cumulative Covid-19 cases",
    "text": "1.1 Mapping the time course of the cumulative Covid-19 cases\n\nlibrary(ggrepel)\n\n#> Loading required package: ggplot2\n\nlibrary(scales)\nlibrary(lubridate)\n\n#> \n#> Attaching package: 'lubridate'\n\n\n#> The following objects are masked from 'package:base':\n#> \n#>     date, intersect, setdiff, union\n\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr   1.1.2     ✔ stringr 1.5.0\n#> ✔ forcats 1.0.0     ✔ tibble  3.2.1\n#> ✔ purrr   1.0.1     ✔ tidyr   1.3.0\n#> ✔ readr   2.1.4\n\n\n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ readr::col_factor() masks scales::col_factor()\n#> ✖ purrr::discard()    masks scales::discard()\n#> ✖ dplyr::filter()     masks stats::filter()\n#> ✖ dplyr::lag()        masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(maps)\n\n#> \n#> Attaching package: 'maps'\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     map\n\nlibrary(mapdata)\nlibrary(ggplot2)\n\n\n\nworld_data <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\", show_col_types = FALSE)\n\nworld_data <- world_data %>% \n  select(date, continent, location, total_cases) %>% \n  filter(!is.na(total_cases))\n\nworld_data$date <- as.Date(world_data$date)\n\ndesired_countries <- c(\"Europe\", \"France\", \"Germany\", \"Spain\", \"United Kingdom\", \"United States\")\nselected_data <- world_data %>% filter(location %in% desired_countries)\n\n# First challenge\n\nggplot(selected_data, aes(x = date, y = total_cases, color = location , group = location)) +\n  geom_line(linewidth = 1) +\n  geom_label_repel(data = selected_data %>% filter(date == max(date)), aes(label = location, x = date, y = total_cases), size = 3, box.padding = unit(0.35, \"lines\"), point.padding = unit(0.5, \"lines\"), show.legend = FALSE) +\n  labs(title = \"Covid-19 Confirmed Cases Worldwide\", subtitle = \"As of 19/04/2022\", y = \"Cumulative Cases\", x = \"Continent/Country\") +\n  scale_y_continuous(labels = scales::comma_format()) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%B '%y\") +\n  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"bottom\") +\n  guides(color = guide_legend(title = \" \"), shape = guide_legend(title = \"Country\", override.aes = list(size = 6))) +\n  theme(legend.title = element_text(size = 12), legend.text = element_text(size = 10))\n\n\n\n\n\n\n\n# Second challenge\n\ncovid_data <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\",show_col_types = FALSE)\n\ncovid_data <- covid_data %>%\n  select(location, date, total_cases, total_deaths, population) %>%\n  filter(!is.na(total_cases), !is.na(total_deaths))\n\ncovid_data$mortality_rate <- covid_data$total_deaths / covid_data$population\n\nlatest_data <- covid_data %>%\n  group_by(location) %>%\n  slice_tail(n = 1)\n\nlatest_data <- latest_data %>%\n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n  )) %>%\n  distinct()\n\nworld <- map_data(\"world\")\nmap_data <- right_join(world, latest_data, by = c(\"region\" = \"location\"))\n\nplot_data <- ggplot() +\n  geom_map(data = map_data, map = map_data, aes(map_id = region, fill = mortality_rate),\n           color = \"gray\", size = 0.1) +\n  expand_limits(x = world$long, y = world$lat) +\n  scale_fill_gradient(low = \"red\", high = \"black\", name = \"Mortality Rate\",\n                      labels = scales::percent_format()) +\n  labs(title = \"Confirmed COVID-19 deaths relative to the size of the population\",\n       subtitle = \"Around 6.2 Million confirmed COVID-19 deaths worldwide\") +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n        plot.subtitle = element_text(hjust = 0.5, size = 10),\n        legend.position = \"right\",\n        legend.title.align = 0.5,\n        legend.text = element_text(size = 8),\n        legend.title = element_text(size = 10),\n        panel.background = element_rect(fill = \"transparent\", color = \"white\"))\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n\nprint(plot_data)"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Sales analysis: This analyzes the sales by location (state) with a bar plot. \nSome business insights for bike sellers is created in this section. Two analyses based on two important categories (year and state) have been made.\n\n1 Code:\n\nlibrary(ggplot2)\nlibrary(lubridate)\n\n#> \n#> Attaching package: 'lubridate'\n\n\n#> The following objects are masked from 'package:base':\n#> \n#>     date, intersect, setdiff, union\n\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr   1.1.2     ✔ stringr 1.5.0\n#> ✔ forcats 1.0.0     ✔ tibble  3.2.1\n#> ✔ purrr   1.0.1     ✔ tidyr   1.3.0\n#> ✔ readr   2.1.4\n\n\n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(scales)\n\n#> \n#> Attaching package: 'scales'\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     discard\n#> \n#> The following object is masked from 'package:readr':\n#> \n#>     col_factor\n\nlibrary(readr)\nlibrary(purrr)\n\n\nbikes_tbl      <- read_excel(path = \"00_data/01_raw_data/bikes.xlsx\")\norderlines_tbl <- read_excel(\"00_data/01_raw_data/orderlines.xlsx\")\n\n#> New names:\n#> • `` -> `...1`\n\nbikeshops_tbl  <- read_excel(\"00_data/01_raw_data/bikeshops.xlsx\")\n\n\n\nleft_join(orderlines_tbl, bikes_tbl, by = c(\"product.id\" = \"bike.id\"))\n\n\n\n  \n\n\nbike_orderlines_joined_tbl <- orderlines_tbl %>%\n  left_join(bikes_tbl, by = c(\"product.id\" = \"bike.id\")) %>%\n  left_join(bikeshops_tbl, by = c(\"customer.id\" = \"bikeshop.id\"))\nbike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%\n  separate(col    = location,\n           into   = c(\"city\", \"state\"),\n           sep    = \", \") %>%\n  \n  mutate(total.price = price * quantity) %>%\n  select(-...1, -gender) %>%\n  select(-ends_with(\".id\")) %>%\n  bind_cols(bike_orderlines_joined_tbl %>% select(order.id)) %>% \n  select(order.id, contains(\"order\"), contains(\"model\"), contains(\"location\"),\n         price, quantity, total.price,\n         everything()) %>%\n  rename(bikeshop = name) %>%\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\n\n\nsales_by_location_tbl <- bike_orderlines_wrangled_tbl %>%\n  select(state, total_price) %>%\n  mutate(location = str_to_title(str_replace_all(state, fixed(\"_\"), \" \"))) %>%\n  group_by(location) %>% \n  summarize(sales = sum(total_price)) %>%\n  \n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n\nsales_by_location_tbl %>%\n  ggplot(aes(x = location, y = sales)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_col(fill = \"#6D8dD1\") + \n  geom_label(aes(label = sales_text)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title    = ,\n    subtitle = ,\n    x = \"\", \n    y = \"Revenue\"\n  )\n\n#> `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nsales_by_location_year_tbl <- bike_orderlines_wrangled_tbl %>%\n  select(order_date, total_price, state) %>%\n  mutate(year = year(order_date)) %>%\n  group_by(year, state) %>%\n  summarise(sales = sum(total_price)) %>%\n  ungroup() %>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#> `summarise()` has grouped output by 'year'. You can override using the\n#> `.groups` argument.\n\nsales_by_location_year_tbl %>%\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  geom_col() +\n  facet_wrap(~ state) +\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = ,\n    subtitle = ,\n    fill = \"Main category\",\n  )"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "Getting data via an API & web scraping:\n\n1 Code:\n\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(rvest)\nlibrary(tibble)\nlibrary(dplyr)\n\n#> \n#> Attaching package: 'dplyr'\n\n\n#> The following objects are masked from 'package:stats':\n#> \n#>     filter, lag\n\n\n#> The following objects are masked from 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(purrr)\n\n#> \n#> Attaching package: 'purrr'\n\n\n#> The following object is masked from 'package:jsonlite':\n#> \n#>     flatten\n\n## First Challenge\n\nSys.setenv(OPENWEATHERMAP_API_KEY = \"7471c3bd36b596b3b489afb5e04d2a61\")\ncity <- 'London'\nendpoint <- paste0('http://api.openweathermap.org/data/2.5/weather?q=', city, '&appid=', Sys.getenv(\"OPENWEATHERMAP_API_KEY\"))\nresponse <- GET(endpoint)\n\n\nif (status_code(response) == 200) {\n  raw_content <- content(response, as = \"raw\")\n  char_content <- rawToChar(raw_content)\n  data <- fromJSON(char_content)\n  temperature <- data$main$temp\n  humidity <- data$main$humidity\n  description <- data$weather[1]$description\n  description <- tolower(description)\n  \n\n  cat(\"City:\", city, \"\\n\")\n  cat(\"Temperature:\", temperature, \"K\\n\")\n  cat(\"Humidity:\", humidity, \"%\\n\")\n} else {\n  print(\"Request failed.\")\n}\n\n#> City: London \n#> Temperature: 297.44 K\n#> Humidity: 35 %\n\n## Second challenge\n\n\nurl2 <- 'https://www.radon-bikes.de/e-bike/trekking/'\nhtml2 <- read_html(url2)\n\n### model\n\ntrekking_ebike <- html2 %>% html_nodes(css = \".row > h2\") %>%\n  html_text() %>% as_tibble()\n### price\n\ntrekking_ebike <- trekking_ebike %>% mutate(new_col=(html2 %>% html_nodes(css =\n  \".currency_eur .m-serienpanel__price--active\") %>% \n  html_text() %>% str_remove_all(' €')))\n### column names\n\ntrekking_ebike <- trekking_ebike %>% set_names(c('model', 'price'))\nview(trekking_ebike)"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sajjad’s Lab Journal",
    "section": "",
    "text": "Welcome to my digital space, where knowledge meets innovation and curiosity paves the way for groundbreaking discoveries. As a Master’s student at TUHH (Technical University of Hamburg), I invite you to embark on a journey through the realms of cutting-edge research and transformative ideas."
  },
  {
    "objectID": "index.html#welcome-to-mylabjournal-explore-my-exciting-academic-journey-by-selecting-from-the-following-menus",
    "href": "index.html#welcome-to-mylabjournal-explore-my-exciting-academic-journey-by-selecting-from-the-following-menus",
    "title": "Sajjad’s Lab Journal",
    "section": "Welcome to MyLabJournal! Explore my exciting academic journey by selecting from the following menus:",
    "text": "Welcome to MyLabJournal! Explore my exciting academic journey by selecting from the following menus:\n\nTidyverse: Dive into the world of Tidyverse, where data analysis becomes a breeze.\nData Acquisition: Discover the art of gathering valuable datasets.\nData Wrangling: Master the art of transforming raw data into meaningful insights.\nData Visualization: Unleash your creativity and bring data to life through captivating visualizations.\n\nClick on your preferred menu and let’s embark on an adventure of knowledge and discovery together!"
  },
  {
    "objectID": "04_data_visualization.html",
    "href": "04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Data Visualization:"
  },
  {
    "objectID": "04_data_visualization.html#mapping-the-time-course-of-the-cumulative-covid-19-cases",
    "href": "04_data_visualization.html#mapping-the-time-course-of-the-cumulative-covid-19-cases",
    "title": "Data Visualization",
    "section": "Mapping the time course of the cumulative Covid-19 cases",
    "text": "Mapping the time course of the cumulative Covid-19 cases\n\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(maps)\nlibrary(mapdata)\nlibrary(ggplot2)\n\n\n\nworld_data <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\", show_col_types = FALSE)\n\nworld_data <- world_data %>% \n  select(date, continent, location, total_cases) %>% \n  filter(!is.na(total_cases))\n\nworld_data$date <- as.Date(world_data$date)\n\ndesired_countries <- c(\"Europe\", \"France\", \"Germany\", \"Spain\", \"United Kingdom\", \"United States\")\nselected_data <- world_data %>% filter(location %in% desired_countries)\n\n# First challenge\n\nggplot(selected_data, aes(x = date, y = total_cases, color = location , group = location)) +\n  geom_line(linewidth = 1) +\n  geom_label_repel(data = selected_data %>% filter(date == max(date)), aes(label = location, x = date, y = total_cases), size = 3, box.padding = unit(0.35, \"lines\"), point.padding = unit(0.5, \"lines\"), show.legend = FALSE) +\n  labs(title = \"Covid-19 Confirmed Cases Worldwide\", subtitle = \"As of 19/04/2022\", y = \"Cumulative Cases\", x = \"Continent/Country\") +\n  scale_y_continuous(labels = scales::comma_format()) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%B '%y\") +\n  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"bottom\") +\n  guides(color = guide_legend(title = \" \"), shape = guide_legend(title = \"Country\", override.aes = list(size = 6))) +\n  theme(legend.title = element_text(size = 12), legend.text = element_text(size = 10))\n\n\n\n\n\n\n\n# Second challenge\n\ncovid_data <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\",show_col_types = FALSE)\n\ncovid_data <- covid_data %>%\n  select(location, date, total_cases, total_deaths, population) %>%\n  filter(!is.na(total_cases), !is.na(total_deaths))\n\ncovid_data$mortality_rate <- covid_data$total_deaths / covid_data$population\n\nlatest_data <- covid_data %>%\n  group_by(location) %>%\n  slice_tail(n = 1)\n\nlatest_data <- latest_data %>%\n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location\n  )) %>%\n  distinct()\n\nworld <- map_data(\"world\")\nmap_data <- right_join(world, latest_data, by = c(\"region\" = \"location\"))\n\nplot_data <- ggplot() +\n  geom_map(data = map_data, map = map_data, aes(map_id = region, fill = mortality_rate),\n           color = \"gray\", size = 0.1) +\n  expand_limits(x = world$long, y = world$lat) +\n  scale_fill_gradient(low = \"red\", high = \"black\", name = \"Mortality Rate\",\n                      labels = scales::percent_format()) +\n  labs(title = \"Confirmed COVID-19 deaths relative to the size of the population\",\n       subtitle = \"Around 6.2 Million confirmed COVID-19 deaths worldwide\") +\n  theme_void() +\n  theme(plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n        plot.subtitle = element_text(hjust = 0.5, size = 10),\n        legend.position = \"right\",\n        legend.title.align = 0.5,\n        legend.text = element_text(size = 8),\n        legend.title = element_text(size = 10),\n        panel.background = element_rect(fill = \"transparent\", color = \"white\"))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\nprint(plot_data)"
  },
  {
    "objectID": "01_tidyverse.html",
    "href": "01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Sales analysis: This analyzes the sales by location (state) with a bar plot. \nSome business insights for bike sellers is created in this section. Two analyses based on two important categories (year and state) have been made.\n\nCode:\n\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(scales)\nlibrary(readr)\nlibrary(purrr)\n\n\nbikes_tbl      <- read_excel(path = \"00_data/01_raw_data/bikes.xlsx\")\norderlines_tbl <- read_excel(\"00_data/01_raw_data/orderlines.xlsx\")\n\nNew names:\n• `` -> `...1`\n\nbikeshops_tbl  <- read_excel(\"00_data/01_raw_data/bikeshops.xlsx\")\n\n\n\nleft_join(orderlines_tbl, bikes_tbl, by = c(\"product.id\" = \"bike.id\"))\n\n# A tibble: 15,644 × 15\n   ...1  order.id order.line order.date          customer.id product.id quantity\n   <chr>    <dbl>      <dbl> <dttm>                    <dbl>      <dbl>    <dbl>\n 1 1            1          1 2015-01-07 00:00:00           2       2681        1\n 2 2            1          2 2015-01-07 00:00:00           2       2411        1\n 3 3            2          1 2015-01-10 00:00:00          10       2629        1\n 4 4            2          2 2015-01-10 00:00:00          10       2137        1\n 5 5            3          1 2015-01-10 00:00:00           6       2367        1\n 6 6            3          2 2015-01-10 00:00:00           6       1973        1\n 7 7            3          3 2015-01-10 00:00:00           6       2422        1\n 8 8            3          4 2015-01-10 00:00:00           6       2655        1\n 9 9            3          5 2015-01-10 00:00:00           6       2247        1\n10 10           4          1 2015-01-11 00:00:00          22       2408        1\n# ℹ 15,634 more rows\n# ℹ 8 more variables: model <chr>, model.year <dbl>, frame.material <chr>,\n#   weight <dbl>, price <dbl>, category <chr>, gender <chr>, url <chr>\n\nbike_orderlines_joined_tbl <- orderlines_tbl %>%\n  left_join(bikes_tbl, by = c(\"product.id\" = \"bike.id\")) %>%\n  left_join(bikeshops_tbl, by = c(\"customer.id\" = \"bikeshop.id\"))\nbike_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%\n  separate(col    = location,\n           into   = c(\"city\", \"state\"),\n           sep    = \", \") %>%\n  \n  mutate(total.price = price * quantity) %>%\n  select(-...1, -gender) %>%\n  select(-ends_with(\".id\")) %>%\n  bind_cols(bike_orderlines_joined_tbl %>% select(order.id)) %>% \n  select(order.id, contains(\"order\"), contains(\"model\"), contains(\"location\"),\n         price, quantity, total.price,\n         everything()) %>%\n  rename(bikeshop = name) %>%\n  set_names(names(.) %>% str_replace_all(\"\\\\.\", \"_\"))\n\n\n\nsales_by_location_tbl <- bike_orderlines_wrangled_tbl %>%\n  select(state, total_price) %>%\n  mutate(location = str_to_title(str_replace_all(state, fixed(\"_\"), \" \"))) %>%\n  group_by(location) %>% \n  summarize(sales = sum(total_price)) %>%\n  \n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n\nsales_by_location_tbl %>%\n  ggplot(aes(x = location, y = sales)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  geom_col(fill = \"#6D8dD1\") + \n  geom_label(aes(label = sales_text)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title    = ,\n    subtitle = ,\n    x = \"\", \n    y = \"Revenue\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsales_by_location_year_tbl <- bike_orderlines_wrangled_tbl %>%\n  select(order_date, total_price, state) %>%\n  mutate(year = year(order_date)) %>%\n  group_by(year, state) %>%\n  summarise(sales = sum(total_price)) %>%\n  ungroup() %>%\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\nsales_by_location_year_tbl %>%\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  geom_col() +\n  facet_wrap(~ state) +\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  labs(\n    title = ,\n    subtitle = ,\n    fill = \"Main category\",\n  )"
  },
  {
    "objectID": "02_data_acquisition.html",
    "href": "02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "Getting data via an API & web scraping:\n\nCode:\n\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(rvest)\nlibrary(tibble)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(stringr)\nlibrary(purrr)\n\n\nAttaching package: 'purrr'\n\n\nThe following object is masked from 'package:jsonlite':\n\n    flatten\n\n## First Challenge\n\nSys.setenv(OPENWEATHERMAP_API_KEY = \"7471c3bd36b596b3b489afb5e04d2a61\")\ncity <- 'London'\nendpoint <- paste0('http://api.openweathermap.org/data/2.5/weather?q=', city, '&appid=', Sys.getenv(\"OPENWEATHERMAP_API_KEY\"))\nresponse <- GET(endpoint)\n\n\nif (status_code(response) == 200) {\n  raw_content <- content(response, as = \"raw\")\n  char_content <- rawToChar(raw_content)\n  data <- fromJSON(char_content)\n  temperature <- data$main$temp\n  humidity <- data$main$humidity\n  description <- data$weather[1]$description\n  description <- tolower(description)\n  \n\n  cat(\"City:\", city, \"\\n\")\n  cat(\"Temperature:\", temperature, \"K\\n\")\n  cat(\"Humidity:\", humidity, \"%\\n\")\n} else {\n  print(\"Request failed.\")\n}\n\nCity: London \nTemperature: 290.84 K\nHumidity: 61 %\n\n## Second challenge\n\n\nurl2 <- 'https://www.radon-bikes.de/e-bike/trekking/'\nhtml2 <- read_html(url2)\n\n### model\n\ntrekking_ebike <- html2 %>% html_nodes(css = \".row > h2\") %>%\n  html_text() %>% as_tibble()\n### price\n\ntrekking_ebike <- trekking_ebike %>% mutate(new_col=(html2 %>% html_nodes(css =\n  \".currency_eur .m-serienpanel__price--active\") %>% \n  html_text() %>% str_remove_all(' €')))\n### column names\n\ntrekking_ebike <- trekking_ebike %>% set_names(c('model', 'price'))\nview(trekking_ebike)"
  }
]